import os
import torch
import sys
import hydra
from omegaconf import OmegaConf
from torch.utils.data import DataLoader
from src.utils.visualizer import LossVisualizer
from datetime import datetime
from src.datasets.camelyon_dataset import PathologyDataset
from src.datasets.transforms import Compose, HorizontalFlip
from src.losses.combined import MultiTaskLoss
from src.models.multitask_model import MultiTaskModel
from src.utils.metrics import accuracy_from_logits, dice_coefficient
from src.utils.misc import get_device, set_seed


# ä¿è¯åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼ˆä» src/engine è·³ä¸¤çº§ï¼‰
os.chdir(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))


@hydra.main(config_path="../../configs", config_name="defaults", version_base=None)
def main(cfg):
    # ------------------------
    # åˆå§‹åŒ–é…ç½®ä¸ç¯å¢ƒ
    # ------------------------
    set_seed(cfg.seed)
    device = get_device(cfg.device)
    os.makedirs(cfg.log.save_dir, exist_ok=True)

    # ------------------------
    # å°†æ§åˆ¶å°è¾“å‡ºé‡å®šå‘åˆ°æ—¥å¿—æ–‡ä»¶
    # ------------------------
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_dir = cfg.log.save_dir
    os.makedirs(log_dir, exist_ok=True)
    log_path = os.path.join(log_dir, f"train_{timestamp}.log")

    # å°† print åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
    class Logger(object):
        def __init__(self, filename):
            self.terminal = sys.stdout
            self.log = open(filename, "a", encoding="utf-8")

        def write(self, message):
            self.terminal.write(message)
            self.log.write(message)
            self.log.flush()  # å®æ—¶å†™å…¥æ–‡ä»¶

        def flush(self):
            pass  # ä¸ºå…¼å®¹æ€§ä¿ç•™

    sys.stdout = Logger(log_path)
    sys.stderr = sys.stdout  # åŒæ—¶æ•è·é”™è¯¯ä¿¡æ¯

    print(f"[Logger] æ—¥å¿—å·²é‡å®šå‘åˆ°æ–‡ä»¶: {log_path}")
    print("=" * 60)
    print("[INFO] å¯åŠ¨è®­ç»ƒè¿›ç¨‹")
    print(OmegaConf.to_yaml(cfg))
    print("=" * 60)

    # ------------------------
    # æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
    # ------------------------
    transform = Compose([HorizontalFlip(p=0.5)])  # ç¤ºä¾‹ï¼šä»…æ°´å¹³ç¿»è½¬
    train_ds = PathologyDataset(cfg.data.train_images, cfg.data.train_masks, cfg.data.train_labels, transform=transform)
    val_ds = PathologyDataset(cfg.data.val_images, cfg.data.val_masks, cfg.data.val_labels, transform=None)

    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers)
    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)

    # ------------------------
    # æ¨¡å‹ã€æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨
    # ------------------------
    model = MultiTaskModel(
        backbone_name=cfg.model.backbone,
        num_classes=cfg.model.num_classes,
        seg_upsample_to_input=cfg.model.seg_upsample_to_input,
    ).to(device)

    criterion = MultiTaskLoss(
        seg_type=cfg.loss.seg,
        cls_type=cfg.loss.cls,
        seg_weight=cfg.loss.seg_weight,
        cls_weight=cfg.loss.cls_weight,
    )

    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)
    # âœ… æ–°å¢ï¼šåˆå§‹åŒ–å¯è§†åŒ–å¯¹è±¡
    visualizer = LossVisualizer(save_dir=cfg.log.save_dir)

    best_val = -1.0

    # ===============================================================
    # ä¸»è®­ç»ƒå¾ªç¯
    # ===============================================================
    for epoch in range(1, cfg.num_epochs + 1):
        print(f"\n===== [Epoch {epoch:03d}/{cfg.num_epochs}] è®­ç»ƒé˜¶æ®µå¼€å§‹ =====")

        # ---------------- Train ----------------
        model.train()
        run_loss = 0.0
        seg_part, cls_part = 0.0, 0.0  # ç”¨äºè®°å½•å­ä»»åŠ¡æŸå¤±å æ¯”

        for step, (images, masks, labels) in enumerate(train_loader, start=1):
            # === æ•°æ®é€å…¥è®¾å¤‡ ===
            images = images.to(device)
            masks = masks.to(device).float()  # âœ… Dataset å·²æ˜¯ {0,1}ï¼Œä»…ä¿è¯ dtype
            labels = labels.to(device)

            optimizer.zero_grad()

            # === æ¨¡å‹å‰å‘ ===
            seg_logits, cls_logits = model(images)

            # === è®¡ç®—å¤šä»»åŠ¡æŸå¤± ===
            loss, parts = criterion(seg_logits, masks, cls_logits, labels)
            loss.backward()
            optimizer.step()

            run_loss += loss.item() * images.size(0)
            seg_part += parts.get("seg_loss", 0)
            cls_part += parts.get("cls_loss", 0)

            # === æ—¥å¿—æ‰“å° ===
            if step % 50 == 0 or step == 1:
                seg_mean = seg_logits.mean().item()
                cls_mean = cls_logits.mean().item()
                print(
                    f"[Train Step {step:04d}] "
                    f"loss={loss.item():.4f} "
                    f"(seg={parts.get('seg_loss', 0):.4f}, cls={parts.get('cls_loss', 0):.4f}) "
                    f"mask_range=({masks.min().item():.1f},{masks.max().item():.1f}) "
                    f"logit_mean(seg={seg_mean:.3f}, cls={cls_mean:.3f})"
                )

                # å¼‚å¸¸æ£€æµ‹
                if torch.isnan(loss):
                    print("âŒ [é”™è¯¯] æ£€æµ‹åˆ° NaNï¼Œè¯·æ£€æŸ¥å­¦ä¹ ç‡æˆ–æ•°æ®è¾“å…¥ï¼")
                    return

        train_loss = run_loss / len(train_ds)
        avg_seg = seg_part / max(len(train_loader), 1)
        avg_cls = cls_part / max(len(train_loader), 1)
        print(f"[Train Summary] train_loss={train_loss:.4f} | seg_loss={avg_seg:.4f} | cls_loss={avg_cls:.4f}")

        # ---------------- Validate ----------------
        print(f"----- [Epoch {epoch:03d}] éªŒè¯é˜¶æ®µå¼€å§‹ -----")
        model.eval()
        val_loss, dice_sum, acc_sum, n_batches = 0.0, 0.0, 0.0, 0

        with torch.no_grad():
            for step, (images, masks, labels) in enumerate(val_loader, start=1):
                images = images.to(device)
                masks = masks.to(device).float()  # âœ… ä¸å†é™¤255ï¼Œä¿æŒä¸€è‡´
                labels = labels.to(device)

                seg_logits, cls_logits = model(images)
                loss, parts = criterion(seg_logits, masks, cls_logits, labels)

                val_loss += loss.item() * images.size(0)
                dice = dice_coefficient(torch.sigmoid(seg_logits), masks)
                acc = accuracy_from_logits(cls_logits, labels)

                dice_sum += dice.item()
                acc_sum += acc
                n_batches += 1

                print(f"[DEBUG] batch={step:02d}, dice={dice.item():.4f}, acc={acc:.4f}")

                if step == 1:
                    print(f"[DEBUG] seg_logits range=({seg_logits.min().item():.3f},{seg_logits.max().item():.3f}), "
                          f"sigmoid_mean={torch.sigmoid(seg_logits).mean().item():.3f}")
                pred = torch.sigmoid(seg_logits)
                print(f"pred mean={pred.mean().item():.3f}, pred>0.9æ¯”ä¾‹={(pred > 0.9).float().mean().item():.3f}")

                # æ¯éš”è‹¥å¹² batch æ‰“å°ä¸€æ¬¡éªŒè¯æ—¥å¿—
                if step % 20 == 0 or step == 1:
                    print(
                        f"[Val Step {step:03d}] "
                        f"val_loss={loss.item():.4f} "
                        f"dice={dice:.4f}, acc={acc:.4f} "
                        f"mask_range=({masks.min().item():.1f},{masks.max().item():.1f}) "
                        f"logit_mean(seg={seg_logits.mean().item():.3f})"
                    )

        # === éªŒè¯æŒ‡æ ‡æ±‡æ€» ===
        val_loss /= len(val_ds)
        val_dice = dice_sum / max(n_batches, 1)
        val_acc = acc_sum / max(n_batches, 1)

        # === å¼‚å¸¸æ£€æµ‹ ===
        if val_dice > 1.0 or val_dice < 0:
            print(f"âš ï¸ [å¼‚å¸¸] val_dice={val_dice:.4f} è¶…å‡º [0,1] èŒƒå›´ï¼Œå¯èƒ½æ˜¯ mask æœªå½’ä¸€åŒ–ã€‚")
        if val_loss < 0:
            print(f"âš ï¸ [å¼‚å¸¸] val_loss={val_loss:.4f} ä¸ºè´Ÿï¼Œè¯·æ£€æŸ¥æŸå¤±å‡½æ•°å®ç°ã€‚")

        print(f"[Validate Summary] val_loss={val_loss:.4f} | val_dice={val_dice:.4f} | val_acc={val_acc:.4f}")

        # âœ… è®°å½•å½“å‰ epoch æŸå¤±æ›²çº¿
        visualizer.update(
            epoch=epoch,
            train_losses={"seg": avg_seg, "cls": avg_cls, "total": train_loss},
            val_losses={"total": val_loss, "dice": val_dice, "acc": val_acc}
        )

        # === ä¿å­˜æœ€ä½³æ¨¡å‹ ===
        score = (val_dice + val_acc) / 2.0
        if score > best_val and cfg.log.save_ckpt:
            best_val = score
            ckpt_path = os.path.join(cfg.log.save_dir, "best.pt")
            torch.save({"model": model.state_dict(), "cfg": OmegaConf.to_container(cfg)}, ckpt_path)
            print(f"âœ… [INFO] å·²ä¿å­˜æœ€ä¼˜æ¨¡å‹åˆ°: {ckpt_path}")

    print(f"ğŸ¯ è®­ç»ƒå®Œæˆï¼Œæœ€ä½³éªŒè¯è¯„åˆ†: {best_val:.4f}")

if __name__ == "__main__":
    main()
